{
  "happy_path": {
    "description": "All approvals, no modifications",
    "node_responses": {
      "query_generator_base": {
        "queries": [
          "machine learning safety verification"
        ]
      },
      "synthesize_literature_review": {
        "knowledge_gap": "Limited formal verification methods for ML safety",
        "synthesized_summary": "Current research focuses on statistical approaches...",
        "justification": "Gap identified through systematic review",
        "is_novel": true
      },
      "formulate_plan": {
        "content": "Research Plan: Develop formal verification framework for ML safety with focus on neural network verification and safety guarantees."
      },
      "review_novelty": {
        "score": 0.8,
        "justification": "Novel integration of formal methods with ML safety"
      },
      "review_feasibility": {
        "score": 0.75,
        "justification": "Technically feasible with existing verification tools"
      },
      "synthesize_review": {
        "is_approved": true,
        "final_summary": "Proposal approved with strong scores on novelty and feasibility"
      }
    },
    "literature_responses": [
      "Formal verification of neural networks has gained attention, with research focusing on robustness properties and safety constraints.",
      "Machine learning safety literature emphasizes the need for verification methods that can provide guarantees about system behavior.",
      "Recent work in ML safety verification shows promise but lacks comprehensive frameworks for practical deployment."
    ]
  },
  "revision_cycle": {
    "description": "Tests the revision loop with initial rejection",
    "node_responses": {
      "query_generator_base": {
        "queries": [
          "AI safety in autonomous systems"
        ]
      },
      "synthesize_literature_review": {
        "knowledge_gap": "Need better safety frameworks for autonomous AI",
        "synthesized_summary": "Autonomous AI safety research is fragmented...",
        "justification": "Multiple gaps identified in current approaches",
        "is_novel": true
      },
      "formulate_plan": {
        "content": "Research Plan: Create comprehensive safety framework for autonomous AI systems."
      },
      "review_novelty": {
        "score": 0.6,
        "justification": "Somewhat novel but similar work exists"
      },
      "review_feasibility": {
        "score": 0.5,
        "justification": "Challenging scope, may need to be narrowed"
      },
      "synthesize_review": {
        "is_approved": false,
        "final_summary": "Proposal needs revision - scope too broad, feasibility concerns"
      }
    },
    "literature_responses": [
      "Autonomous AI safety is a broad field with work spanning robotics, decision-making, and human-AI interaction."
    ]
  },
  "user_modifications": {
    "description": "User provides custom queries and feedback",
    "node_responses": {
      "query_generator_base": {
        "queries": [
          "custom user query from interrupt"
        ]
      },
      "synthesize_literature_review": {
        "knowledge_gap": "User-refined knowledge gap",
        "synthesized_summary": "Literature review based on user input...",
        "justification": "User provided specific direction",
        "is_novel": true
      },
      "formulate_plan": {
        "content": "Research Plan: User-guided research direction with specific focus areas."
      },
      "review_novelty": {
        "score": 0.7,
        "justification": "User input improved novelty"
      },
      "review_feasibility": {
        "score": 0.8,
        "justification": "User guidance improved feasibility"
      },
      "synthesize_review": {
        "is_approved": true,
        "final_summary": "Approved with user improvements"
      }
    },
    "literature_responses": [
      "Literature response incorporating user-provided direction and custom query focus."
    ]
  }
}